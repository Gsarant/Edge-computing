{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "5fbe1cc5-c81b-4adc-be5b-54454b506af3",
     "kernelId": "ce0ac3fc-31cd-4441-a20a-a8865cd9c685"
    },
    "id": "qvn7GWvXVain"
   },
   "source": [
    "# Import Libraries  Initialize Var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "abb78b3b-33f1-4f64-ad7f-9e0d51193c8a",
     "kernelId": "ce0ac3fc-31cd-4441-a20a-a8865cd9c685",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!apt-get update -y\n",
    "\n",
    "!apt install libgl1-mesa-glx -y\n",
    "!apt-get install -y xxd \n",
    "\n",
    "!pip install matplotlib\n",
    "!pip install opencv-python\n",
    "!/usr/bin/python -m pip install --upgrade pip\n",
    "!pip install -q tensorflow-model-optimization\n",
    "print('Depencies Installed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34030,
     "status": "ok",
     "timestamp": 1637329867334,
     "user": {
      "displayName": "Ιωάννης Σαραντόπουλος",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10062810659420397031"
     },
     "user_tz": -120
    },
    "gradient": {
     "editing": false,
     "id": "58f08553-6297-4d5e-a9f6-d1333ac361d0",
     "kernelId": "ce0ac3fc-31cd-4441-a20a-a8865cd9c685"
    },
    "id": "1CuDi3UkVYX4",
    "outputId": "1e40ddcd-f6e3-4ca2-eb58-16dc3b644c97"
   },
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import cv2 \n",
    "\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "BATCH_SIZE = 32\n",
    "WIDTH=240\n",
    "HEIGHT=240\n",
    "IMG_SIZE = (WIDTH, HEIGHT)\n",
    "filename=\"model_count_insects_final_2\"\n",
    "project_folder=''\n",
    "image_dataset_folder=\"images_sets\"\n",
    "train_image_folder=os.path.join(os.path.join(image_dataset_folder,'images_train_set'))\n",
    "test_image_folder=os.path.join(os.path.join(image_dataset_folder,'images_test_set'))\n",
    "\n",
    "path_saved_model=os.path.join(project_folder,'saved_models',f\"{filename}.h5\")\n",
    "path_saved_model_tflite=os.path.join(project_folder,'saved_models',f\"{filename}.tflite\")\n",
    "path_saved_model_tflite_quant=os.path.join(project_folder,'saved_models',f\"{filename}_quant.tflite\")\n",
    "path_saved_model_tflite_quant_tpu=os.path.join(project_folder,'saved_models',f\"{filename}_quant_tpu.tflite\")\n",
    "\n",
    "print('Import libraries')\n",
    "print('Initialize Vars')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "cf7befa8-0771-4143-8382-4da064c52b2b",
     "kernelId": "ce0ac3fc-31cd-4441-a20a-a8865cd9c685",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    for h in logging.getLogger().handlers:\n",
    "        logging.getLogger().removeHandler(h)\n",
    "except:\n",
    "    pass\n",
    "mylogs = logging.getLogger(__name__)\n",
    "mylogs.setLevel(logging.INFO)\n",
    "# Handler - 1\n",
    "h_file = logging.FileHandler(f'{filename}aa.log')\n",
    "fileformat = logging.Formatter(\"%(asctime)s:%(levelname)s:%(message)s\")\n",
    "h_file.setLevel(logging.INFO)\n",
    "h_file.setFormatter(fileformat)\n",
    "\n",
    "h_stream = logging.StreamHandler()\n",
    "h_streamformat = logging.Formatter(\"%(asctime)s:   %(message)s\")\n",
    "h_stream.setLevel(logging.INFO)\n",
    "h_stream.setFormatter(h_streamformat)\n",
    "\n",
    "# Adding all handlers to the logs\n",
    "mylogs.addHandler(h_file)\n",
    "mylogs.addHandler(h_stream)\n",
    "\n",
    "        \n",
    "mylogs.info(f'Libraries Imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "c6e9ab45-5ecd-47f5-929d-3bc37fb29aa8",
     "kernelId": "ce0ac3fc-31cd-4441-a20a-a8865cd9c685",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def a(predict,label):\n",
    "    \"\"\"α=1-|Μc-Αc|/Mc\"\"\"\n",
    "    #print(f'1-|{label}-{predict}|/{label}')\n",
    "\n",
    "    return 1-abs(float(label)-float(predict))/float(label) if float(label)!=0.0 else  1-abs(float(label)-float(predict))\n",
    "\n",
    "def model_evaluate(model_file_path,dataset,print_commends=False,show_images=False):\n",
    "    try:\n",
    "        model = tf.keras.models.load_model(model_file_path)\n",
    "        mylogs.info(f'Load model {model_file_path}')\n",
    "    except :\n",
    "        mylogs.error('error')\n",
    "\n",
    "    batch_prediction_floor = []\n",
    "    batch_prediction_round = []\n",
    "    batch_truth = []\n",
    "    count=0\n",
    "    sum_a=0 \n",
    "    for image, label in dataset.unbatch():\n",
    "        batch_truth.append(label)\n",
    "\n",
    "        input_data =(np.float32(image)/255.0)\n",
    "        input_data = np.expand_dims(input_data, axis=0)\n",
    "        \n",
    "        output_data=model.predict(input_data)\n",
    "\n",
    "        predictions=np.floor(np.array(output_data).item(0))\n",
    "        predictions_round=np.around(np.array(output_data).item(0))\n",
    "        count=count+1\n",
    "        batch_prediction_floor.append(predictions)\n",
    "        batch_prediction_round.append(predictions_round)\n",
    "        ac=a(np.array(output_data).item(0) , label) \n",
    "        sum_a=sum_a+ac \n",
    "        if show_images==True:\n",
    "            plt.imshow(image)\n",
    "            plt.show()\n",
    "        \n",
    "        if print_commends==True:\n",
    "            if label!=predictions_round:\n",
    "                mylogs.info(f'{\"*****\" if label==predictions_round else \"\"} label={label} predict={np.array(output_data).item(0)}  round={predictions_round}')\n",
    "                mylogs.info(f' accurancy a ={ac}')\n",
    "       \n",
    "\n",
    "    mylogs.info(f' a= {sum_a/count}')\n",
    "    mylogs.info(f'Number of test Images {count}')\n",
    "    tflite_accuracy = tf.keras.metrics.Accuracy()\n",
    "    tflite_accuracy(batch_prediction_floor, batch_truth)\n",
    "    mylogs.info(\"TF Lite accuracy: {:.3%}\".format(tflite_accuracy.result()))\n",
    "\n",
    "\n",
    "    tflite_accuracy_round = tf.keras.metrics.Accuracy()\n",
    "    tflite_accuracy_round(batch_prediction_round, batch_truth)\n",
    "    mylogs.info(\"TF Lite accuracy round : {:.3%}\".format(tflite_accuracy_round.result()))\n",
    "\n",
    "    dataset_a=dataset.map(lambda image,label:(image/255,label),num_parallel_calls=AUTOTUNE)\n",
    "    loss0,mae = model.evaluate(dataset_a,verbose=2)\n",
    "\n",
    "def interpreter_evaluation(model_tflite_file_path,dataset):\n",
    "    interpreter = tf.lite.Interpreter(\n",
    "      model_path=model_tflite_file_path, num_threads=None)\n",
    "\n",
    "    mylogs.info(f'Load interpreter model {path_saved_model_tflite}')\n",
    "\n",
    "    interpreter.allocate_tensors()\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    height = input_details[0]['shape'][1]\n",
    "    width = input_details[0]['shape'][2]\n",
    "\n",
    "    batch_prediction_floor = []\n",
    "    batch_prediction_round = []\n",
    "    batch_truth = []\n",
    "    count=0\n",
    "    plt.figure(figsize=(10, 20))\n",
    "    mylogs.info(f'Wait to evalluate test images......')\n",
    "    sum_a=0\n",
    "    for image, label in dataset.unbatch():\n",
    "        batch_truth.append(label)\n",
    "\n",
    "        input_data =(np.float32(image)/255)\n",
    "        input_data = np.expand_dims(input_data, axis=0).astype(input_details[0][\"dtype\"])\n",
    "\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "        interpreter.invoke()\n",
    "        output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "        predictions=np.floor(np.array(output_data).item(0))\n",
    "        predictions_round=np.around(np.array(output_data).item(0))\n",
    "        count=count+1\n",
    "        batch_prediction_floor.append(predictions)\n",
    "        batch_prediction_round.append(predictions_round)\n",
    "        ac=a(np.array(output_data).item(0) , label) \n",
    "        sum_a=sum_a+ac\n",
    "        \n",
    "    \n",
    "    mylogs.info(f' a= {sum_a/count}')\n",
    "    mylogs.info(f'Number of test Images {count}')\n",
    "    tflite_accuracy = tf.keras.metrics.Accuracy()\n",
    "    tflite_accuracy(batch_prediction_floor, batch_truth)\n",
    "    mylogs.info(\"TF Lite accuracy: {:.3%}\".format(tflite_accuracy.result()))\n",
    "\n",
    "    tflite_accuracy_round = tf.keras.metrics.Accuracy()\n",
    "    tflite_accuracy_round(batch_prediction_round, batch_truth)\n",
    "    mylogs.info(\"TF Lite accuracy round : {:.3%}\".format(tflite_accuracy_round.result()))\n",
    "print('Init Functions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "7449e373-994f-4772-aaf5-ab408aa528de",
     "kernelId": "ce0ac3fc-31cd-4441-a20a-a8865cd9c685"
    },
    "id": "SbB6ZVlQars2"
   },
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "b9b52b40-0fb7-41fb-8b7f-55228373b0df",
     "kernelId": "ce0ac3fc-31cd-4441-a20a-a8865cd9c685",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "imagePaths= []\n",
    "dataset_file_list=os.path.join(image_dataset_folder,'list_insects_14000.txt')\n",
    "\n",
    "with open(dataset_file_list,'r') as f:\n",
    "    imagePaths=eval(f.readline())\n",
    "DATASET_SIZE=len(imagePaths)\n",
    "  \n",
    "\n",
    "def load_images(imagePath):\n",
    "  image = tf.io.read_file(imagePath)\n",
    "  image = tf.image.decode_jpeg(image, channels=3)\n",
    "  image = tf.image.rgb_to_grayscale(image)\n",
    "  #image = tf.image.resize(image, (240, 240)) / 255.0\n",
    "  label=int(tf.strings.split(tf.strings.split(imagePath,'_')[-1],'.')[-2])\n",
    "  return (image, label)\n",
    "\n",
    "mylogs.info(len(imagePaths))\n",
    "\n",
    "train_imagePaths = imagePaths[:int(len(imagePaths)*0.7)]\n",
    "mylogs.info(len(train_imagePaths))\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(train_imagePaths).map(load_images, num_parallel_calls=AUTOTUNE)\n",
    "train_ds = train_ds.cache()\n",
    "\n",
    "train_ds = train_ds.batch(BATCH_SIZE)\n",
    "train_ds = train_ds.prefetch(AUTOTUNE)\n",
    "mylogs.info('train_ds ok')\n",
    "\n",
    "test_imagePaths = imagePaths[int(len(imagePaths)*0.7):]\n",
    "mylogs.info(len(test_imagePaths))\n",
    "\n",
    "val_ds = tf.data.Dataset.from_tensor_slices(test_imagePaths).map(load_images, num_parallel_calls=AUTOTUNE)\n",
    "val_ds = val_ds.cache()\n",
    "val_ds = val_ds.batch(BATCH_SIZE)\n",
    "val_ds = val_ds.prefetch(AUTOTUNE)\n",
    "\n",
    "mylogs.info('val_ds ok')\n",
    "mylogs.info(f'Data set folder \\n Train set size {len(train_ds)}  \\n Validation set size {len(val_ds)}  \\n General size {DATASET_SIZE}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17911,
     "status": "ok",
     "timestamp": 1637329890215,
     "user": {
      "displayName": "Ιωάννης Σαραντόπουλος",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10062810659420397031"
     },
     "user_tz": -120
    },
    "gradient": {
     "editing": false,
     "id": "de93774a-2f65-4032-9f84-45f5e033eb95",
     "kernelId": "ce0ac3fc-31cd-4441-a20a-a8865cd9c685"
    },
    "id": "FT1SXAH7atrI"
   },
   "outputs": [],
   "source": [
    "\n",
    "test_imagePaths= []\n",
    "for image_filename in os.listdir(test_image_folder):\n",
    "  test_imagePaths.append(os.path.join(test_image_folder,image_filename))\n",
    "\n",
    "def load_images(imagePath):\n",
    "  image = tf.io.read_file(imagePath)\n",
    "  image = tf.image.decode_jpeg(image, channels=3)\n",
    "  image = tf.image.rgb_to_grayscale(image)\n",
    "  #image = tf.image.resize(image, (240, 240)) / 255.0\n",
    "  label=int(tf.strings.split(tf.strings.split(imagePath,'_')[-1],'.')[-2])\n",
    "  return (image, label)\n",
    "\n",
    "mylogs.info(len(test_imagePaths))\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices(test_imagePaths).map(load_images, num_parallel_calls=AUTOTUNE)\n",
    "test_ds = test_ds.cache()\n",
    "test_ds = test_ds.batch(BATCH_SIZE)\n",
    "test_ds = test_ds.prefetch(AUTOTUNE)\n",
    "mylogs.info('test_ds ok')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "d7d5523f-3615-46d5-911c-6a9cda18001e",
     "kernelId": "ce0ac3fc-31cd-4441-a20a-a8865cd9c685",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in test_ds.take(1):\n",
    "  for i in range(12):\n",
    "    ax = plt.subplot(3, 4, i + 1)\n",
    "    plt.imshow(images[i][:,:,0],cmap='gray', vmin=0, vmax=255)\n",
    "    plt.title(str(labels[i].numpy()))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "41f57024-a8a1-40ed-acb3-e91fa29a3a30",
     "kernelId": "ce0ac3fc-31cd-4441-a20a-a8865cd9c685"
    }
   },
   "source": [
    "## Load and get accurancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "17ab652e-bfce-4c89-b40f-4294916ea34c",
     "kernelId": "ce0ac3fc-31cd-4441-a20a-a8865cd9c685",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "mylogs.info(path_saved_model)\n",
    "model_evaluate(path_saved_model,test_ds)\n",
    "model_evaluate(path_saved_model,val_ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "2167036a-bf8e-4e59-8a80-4be5fd76557b",
     "kernelId": "ce0ac3fc-31cd-4441-a20a-a8865cd9c685"
    },
    "id": "wc_JjixuWOd3"
   },
   "source": [
    "\n",
    "# Conver* h5 to TFLite\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "707e270a-e740-43d1-b8f2-d7a2eb1aa833",
     "kernelId": "ce0ac3fc-31cd-4441-a20a-a8865cd9c685"
    },
    "id": "AKdslN_tWPYp"
   },
   "outputs": [],
   "source": [
    "# Convert the model to the TensorFlow Lite format with full integer quantization\n",
    "model_lite = tf.keras.models.load_model(path_saved_model)\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_lite)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(path_saved_model_tflite, 'wb') as f:\n",
    "  f.write(tflite_model)\n",
    "\n",
    "mylogs.info(f'Create tflite model {path_saved_model_tflite}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "8acc143f-a186-4c2e-a83b-af819ad9b6f7",
     "kernelId": "ce0ac3fc-31cd-4441-a20a-a8865cd9c685"
    },
    "id": "kN8q3CCmXTsd"
   },
   "source": [
    "## Evaluate TFLite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "f4169312-3d2d-4e13-9988-48f384979e7d",
     "kernelId": "ce0ac3fc-31cd-4441-a20a-a8865cd9c685"
    },
    "id": "cwxuLpfaXUDA"
   },
   "outputs": [],
   "source": [
    "interpreter_evaluation(path_saved_model_tflite,test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "57400575-4122-4a30-9918-7f43ef3fb2cd",
     "kernelId": "ce0ac3fc-31cd-4441-a20a-a8865cd9c685"
    },
    "id": "DkrhpARyXpOt"
   },
   "source": [
    "# Convert To TFLite Quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35654,
     "status": "ok",
     "timestamp": 1637329941114,
     "user": {
      "displayName": "Ιωάννης Σαραντόπουλος",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10062810659420397031"
     },
     "user_tz": -120
    },
    "gradient": {
     "editing": false,
     "id": "5724c4d8-1e54-4c2c-a36b-085e9a9497f3",
     "kernelId": "ce0ac3fc-31cd-4441-a20a-a8865cd9c685"
    },
    "id": "7ccwB89VXrEz",
    "outputId": "02941735-4b54-4bb4-c210-265237bb336f"
   },
   "outputs": [],
   "source": [
    "\n",
    "def representative_data_gen():\n",
    "  \n",
    "  for setimage , setlabel  in train_ds.take(50):\n",
    "    for index in range(len(setimage)):\n",
    "      image = setimage[index]\n",
    "      image = (np.float32(image) / 255.0)\n",
    "      image=np.expand_dims(image, axis=0) \n",
    "      yield [image.astype(np.float32)]\n",
    "\n",
    "model = tf.keras.models.load_model(path_saved_model)\n",
    "mylogs.info(f'Load  model {path_saved_model}')\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "# This enables quantization\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# This sets the representative dataset for quantization\n",
    "#converter.representative_dataset = representative_data_gen\n",
    "converter.representative_dataset =tf.lite.RepresentativeDataset(representative_data_gen)\n",
    "\n",
    "# This ensures that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# For full integer quantization, though supported types defaults to int8 only, we explicitly declare it for clarity.\n",
    "converter.target_spec.supported_types = [tf.int8]\n",
    "# These set the input and output tensors to uint8 (added in r2.3)\n",
    "converter.inference_input_type = tf.int8\n",
    "#converter.inference_input_type = tf.float32\n",
    "converter.inference_output_type = tf.int8\n",
    "tflite_model_quant = converter.convert()\n",
    "\n",
    "with open(path_saved_model_tflite_quant, 'wb') as f:\n",
    "  f.write(tflite_model_quant)\n",
    "\n",
    "mylogs.info(f'Create Quant file {path_saved_model_tflite_quant}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "6dc0efc0-a5cf-4043-a98a-9cf8cfd927c3",
     "kernelId": "ce0ac3fc-31cd-4441-a20a-a8865cd9c685"
    },
    "id": "kJYii-RYXy99"
   },
   "source": [
    "## Evulate Quant model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "320c7703-240c-4271-8723-2da414901847",
     "kernelId": "ce0ac3fc-31cd-4441-a20a-a8865cd9c685",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "interpreter_qt = tf.lite.Interpreter(\n",
    "      model_path=path_saved_model_tflite_quant, num_threads=None)\n",
    "\n",
    "mylogs.info(f'Load interpreter model {path_saved_model_tflite_quant}')\n",
    "\n",
    "\n",
    "interpreter_qt.allocate_tensors()\n",
    "\n",
    "input_details = interpreter_qt.get_input_details()\n",
    "\n",
    "output_details = interpreter_qt.get_output_details()\n",
    "\n",
    "height = input_details[0]['shape'][1]\n",
    "width = input_details[0]['shape'][2]\n",
    "#mylogs.info(f\"height {height}  width {width}\")\n",
    "\n",
    "batch_prediction_floor = []\n",
    "batch_prediction_round = []\n",
    "\n",
    "batch_truth = []\n",
    "count=0\n",
    "sum_a=0\n",
    "sum_a_category_of_images=[0,0,0,0,0,0,0]\n",
    "correct_predict_category_of_images=[0,0,0,0,0,0,0]\n",
    "count_a_category_of_images=[0,0,0,0,0,0,0]\n",
    "for image, label in test_ds.unbatch():\n",
    "  batch_truth.append(label)\n",
    "  \n",
    "  \n",
    "  scale, zero_point = input_details[0]['quantization']\n",
    "  \n",
    "  input_data= (np.float32(image) / 255.0) / (scale*1.0) + (zero_point*1.0)\n",
    "  \n",
    "  input_data = np.expand_dims(input_data, axis=0).astype(input_details[0][\"dtype\"])\n",
    "  \n",
    "  interpreter_qt.set_tensor(input_details[0]['index'], input_data)\n",
    "  interpreter_qt.invoke()\n",
    "  \n",
    "  #prepair output\n",
    "  output_data1 = interpreter_qt.get_tensor(output_details[0]['index'])\n",
    "  \n",
    "  scale, zero_point = output_details[0]['quantization']\n",
    "  \n",
    "  output_data = ((scale*1.0) * (output_data1 - zero_point*1.0))\n",
    "  \n",
    "  ac=a(np.array(output_data).item(0) , label) \n",
    "\n",
    "  sum_a_category_of_images[int(label)]=sum_a_category_of_images[int(label)]+ac\n",
    "  count_a_category_of_images[int(label)]=count_a_category_of_images[int(label)]+1\n",
    "  sum_a=sum_a+ac\n",
    "\n",
    "  predictions=np.floor(np.array(output_data).item(0))\n",
    "  predictions_round=np.around(np.array(output_data).item(0))\n",
    "  if int(label)==predictions_round:\n",
    "    correct_predict_category_of_images[int(label)]=correct_predict_category_of_images[int(label)]+1\n",
    "\n",
    "  count=count+1\n",
    "  batch_prediction_floor.append(predictions)\n",
    "  batch_prediction_round.append(predictions_round)\n",
    "  #image=cv2.putText(np.float32(image),str(predictions_round),(5,25),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,0),1)\n",
    "  #cv2.imwrite(f'predicte_bug_{count}_{predictions_round}.jpg',image)  \n",
    "\n",
    "mylogs.info(f' Mean a = {sum_a/count}')\n",
    "mylogs.info(f'Number of test Images {count}')\n",
    "tflite_accuracy = tf.keras.metrics.Accuracy()\n",
    "tflite_accuracy(batch_prediction_floor, batch_truth)\n",
    "mylogs.info(\"TF Lite accuracy: {:.3%}\".format(tflite_accuracy.result()))\n",
    "\n",
    "tflite_accuracy_round = tf.keras.metrics.Accuracy()\n",
    "tflite_accuracy_round(batch_prediction_round, batch_truth)\n",
    "mylogs.info(\"TF Lite accuracy round : {:.3%}\".format(tflite_accuracy_round.result()))\n",
    "\n",
    "for index in range(0,7):\n",
    "  avg_a_category=sum_a_category_of_images[index]/count_a_category_of_images[index]\n",
    "  mylogs.info(f'Category {index} a={avg_a_category}')\n",
    "  mylogs.info(f'Category {index} total count={count_a_category_of_images[index]} correct round={correct_predict_category_of_images[index]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "456de4f4-7933-461d-ba0f-aea7b212d2d8",
     "kernelId": "ce0ac3fc-31cd-4441-a20a-a8865cd9c685"
    },
    "id": "d4_ST0vZVOf4"
   },
   "source": [
    "\n",
    "\n",
    "# Create CC file for microcontroller\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1182,
     "status": "ok",
     "timestamp": 1637330708963,
     "user": {
      "displayName": "Ιωάννης Σαραντόπουλος",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10062810659420397031"
     },
     "user_tz": -120
    },
    "gradient": {
     "editing": false,
     "id": "d5045560-4455-4906-bcd6-5dce98334864",
     "kernelId": "ce0ac3fc-31cd-4441-a20a-a8865cd9c685"
    },
    "id": "yeBKh3uMTy6D"
   },
   "outputs": [],
   "source": [
    "# Save to disk\n",
    "#!apt-get update --fix-missing\n",
    "\n",
    "path_saved=os.path.join(project_folder,'saved_models')\n",
    "\n",
    "!cd '{path_saved}'\n",
    "\n",
    "!xxd -i '{path_saved_model_tflite_quant}' > '{filename}_quant.cc'\n",
    "#!sed -i 's/{filename}_quant.tflite/model_data_tflite/g'  \"{filename}_quant.cc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "f3aac326-e9af-4301-99c9-16516e23e0d3",
     "kernelId": "ce0ac3fc-31cd-4441-a20a-a8865cd9c685"
    }
   },
   "source": [
    "# Create TensorFlow Lite TPU for Coral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "2b415852-e7ce-4f6e-b857-32813ae7f5d3",
     "kernelId": "ce0ac3fc-31cd-4441-a20a-a8865cd9c685",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "! curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n",
    "\n",
    "! echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" |  tee /etc/apt/sources.list.d/coral-edgetpu.list\n",
    "\n",
    "! apt-get update\n",
    "\n",
    "! apt-get install edgetpu-compiler\t\n",
    "\n",
    "! edgetpu_compiler '{path_saved_model_tflite_quant}' -m 13 -s -o '{path_saved_model_tflite_quant_tpu}'"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOv35xMQfgXtITc7rx2hnfe",
   "collapsed_sections": [
    "kd89tNkScAwE",
    "wc_JjixuWOd3",
    "d4_ST0vZVOf4"
   ],
   "name": "Count_bugs_TFLITE_microcontroller.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
