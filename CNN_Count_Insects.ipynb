{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77b2a9f8-35ef-4831-a2ab-f4ef9c9f5f7c",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "77b2a9f8-35ef-4831-a2ab-f4ef9c9f5f7c",
     "kernelId": "b83cabf1-1f53-48d7-b924-4b8494b9f03d"
    }
   },
   "source": [
    "#  Install depences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3d4d31-8c9d-4a0f-854c-11b09d0cbf8f",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "6d3d4d31-8c9d-4a0f-854c-11b09d0cbf8f",
     "kernelId": "b83cabf1-1f53-48d7-b924-4b8494b9f03d",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!apt-get update -y\n",
    "#!apt-get upgrade -y\n",
    "!apt install libgl1-mesa-glx -y\n",
    "!pip install matplotlib\n",
    "!pip install opencv-python\n",
    "!/usr/bin/python -m pip install --upgrade pip\n",
    "print('Depencies Installed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651c4c11-778a-4b0f-ac35-36e4c6127fdc",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "651c4c11-778a-4b0f-ac35-36e4c6127fdc",
     "kernelId": "b83cabf1-1f53-48d7-b924-4b8494b9f03d"
    }
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc2983f-7f55-460a-9ca6-4e780c4534c2",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "7dc2983f-7f55-460a-9ca6-4e780c4534c2",
     "kernelId": "b83cabf1-1f53-48d7-b924-4b8494b9f03d",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import pathlib\n",
    "import os\n",
    "import datetime\n",
    "import urllib.request\n",
    "import cv2 \n",
    "from random import seed\n",
    "from random import randint\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "\n",
    "\n",
    "print('Librariew Imported')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9a5bb2-4156-4923-bd5c-d6fa33853fe4",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "bf9a5bb2-4156-4923-bd5c-d6fa33853fe4",
     "kernelId": "b83cabf1-1f53-48d7-b924-4b8494b9f03d"
    }
   },
   "source": [
    "# Initialize Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece93a00-9629-472f-9f51-92c9ae942432",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "ece93a00-9629-472f-9f51-92c9ae942432",
     "kernelId": "b83cabf1-1f53-48d7-b924-4b8494b9f03d",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "WIDTH=240\n",
    "HEIGHT=240\n",
    "IMG_SIZE = (WIDTH, HEIGHT)\n",
    "filename=\"Count_insects_final_2\"\n",
    "\n",
    "project_folder=\"\"\n",
    "datadir_local=pathlib.Path('images_sets')\n",
    "\n",
    "dataset_folder_local=os.path.join(datadir_local,\"images_train_set\")\n",
    "\n",
    "\n",
    "check_point_folder=os.path.join(project_folder,'check_point_folder')\n",
    "!mkdir {check_point_folder}\n",
    "\n",
    "log_folder_path=os.path.join(project_folder,'logs')\n",
    "!mkdir {log_folder_path}\n",
    "\n",
    "history_log_folder_path=os.path.join(project_folder,'history_logs')\n",
    "!mkdir {history_log_folder_path}\n",
    "\n",
    "saved_folder_path=os.path.join(project_folder,'saved_models')\n",
    "!mkdir {saved_folder_path}\n",
    "print('Initialize Vars')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79e6de0-5b6c-4904-8724-ed0e848da4e1",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "f79e6de0-5b6c-4904-8724-ed0e848da4e1",
     "kernelId": "b83cabf1-1f53-48d7-b924-4b8494b9f03d",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    for h in logging.getLogger().handlers:\n",
    "        logging.getLogger().removeHandler(h)\n",
    "except:\n",
    "    pass\n",
    "mylogs = logging.getLogger('CNN_Count_insects_final_2')\n",
    "mylogs.setLevel(logging.INFO)\n",
    "# Handler - 1\n",
    "h_file = logging.FileHandler(f'{filename}.log')\n",
    "fileformat = logging.Formatter(\"%(asctime)s:%(levelname)s:%(message)s\")\n",
    "h_file.setLevel(logging.INFO)\n",
    "h_file.setFormatter(fileformat)\n",
    "\n",
    "h_stream = logging.StreamHandler()\n",
    "h_streamformat = logging.Formatter(\"%(asctime)s:   %(message)s\")\n",
    "h_stream.setLevel(logging.INFO)\n",
    "h_stream.setFormatter(h_streamformat)\n",
    "\n",
    "# Adding all handlers to the logs\n",
    "mylogs.addHandler(h_file)\n",
    "mylogs.addHandler(h_stream)\n",
    "mylogs.info('Initialize Log')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42e227e-d71b-4221-8040-008b8b504a37",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "f42e227e-d71b-4221-8040-008b8b504a37",
     "kernelId": "b83cabf1-1f53-48d7-b924-4b8494b9f03d"
    }
   },
   "source": [
    "# Create TF Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d445ca-c93b-4936-8751-7ea017feec81",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "84d445ca-c93b-4936-8751-7ea017feec81",
     "kernelId": "b83cabf1-1f53-48d7-b924-4b8494b9f03d",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "imagePaths= []\n",
    "dataset_file_list=os.path.join(datadir_local,'list_insects_14000.txt')\n",
    "if not os.path.exists(dataset_file_list):\n",
    "  ###\n",
    "  #**********************\n",
    "  DATASET_SIZE=0\n",
    "  for imagefiles in os.listdir(dataset_folder_local):\n",
    "    if imagefiles[-3:]!='txt':\n",
    "      imagePaths.append(os.path.join(dataset_folder_local,imagefiles))\n",
    "      DATASET_SIZE=DATASET_SIZE+1\n",
    "  np.random.shuffle(imagePaths)\n",
    "  with open(dataset_file_list,'w') as f:\n",
    "    f.write(str(imagePaths))\n",
    "  #*********************\n",
    "  ###\n",
    "else:\n",
    "  with open(dataset_file_list,'r') as f:\n",
    "    imagePaths=eval(f.readline())\n",
    "  DATASET_SIZE=len(imagePaths)\n",
    "  \n",
    "\n",
    "def load_images(imagePath):\n",
    "  image = tf.io.read_file(imagePath)\n",
    "  image = tf.image.decode_jpeg(image, channels=3)\n",
    "  image = tf.image.rgb_to_grayscale(image)\n",
    "  #image = tf.image.resize(image, (240, 240)) / 255.0\n",
    "  label=int(tf.strings.split(tf.strings.split(imagePath,'_')[-1],'.')[-2])\n",
    "  return (image, label)\n",
    "\n",
    "mylogs.info(len(imagePaths))\n",
    "\n",
    "train_imagePaths = imagePaths[:int(len(imagePaths)*0.7)]\n",
    "mylogs.info(len(train_imagePaths))\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(train_imagePaths).map(load_images, num_parallel_calls=AUTOTUNE)\n",
    "train_ds = train_ds.cache()\n",
    "#train_ds = train_ds.repeat()\n",
    "train_ds = train_ds.batch(BATCH_SIZE)\n",
    "train_ds = train_ds.prefetch(AUTOTUNE)\n",
    "mylogs.info('train_ds ok')\n",
    "\n",
    "test_imagePaths = imagePaths[int(len(imagePaths)*0.7):]\n",
    "mylogs.info(len(test_imagePaths))\n",
    "\n",
    "val_ds = tf.data.Dataset.from_tensor_slices(test_imagePaths).map(load_images, num_parallel_calls=AUTOTUNE)\n",
    "val_ds = val_ds.cache()\n",
    "#val_ds = val_ds.repeat()\n",
    "val_ds = val_ds.batch(BATCH_SIZE)\n",
    "val_ds = val_ds.prefetch(AUTOTUNE)\n",
    "mylogs.info('val_ds ok')\n",
    "mylogs.info(f'Data set folder {dataset_folder_local} \\n Train set size {len(train_ds)}  \\n Validation set size {len(val_ds)}  \\n General size {DATASET_SIZE}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cf896c-90e1-4e7f-9e3d-272d7d00e390",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "07cf896c-90e1-4e7f-9e3d-272d7d00e390",
     "kernelId": "b83cabf1-1f53-48d7-b924-4b8494b9f03d"
    }
   },
   "source": [
    "# Show sample of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedb72d1-ee52-48da-8fe0-ac1d9df0faec",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "fedb72d1-ee52-48da-8fe0-ac1d9df0faec",
     "kernelId": "b83cabf1-1f53-48d7-b924-4b8494b9f03d",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(12):\n",
    "    ax = plt.subplot(3, 4, i + 1)\n",
    "    plt.imshow(images[i][:,:,0],cmap='gray', vmin=0, vmax=255)\n",
    "    plt.title(str(labels[i].numpy()))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3288fde-b86b-4a86-9b72-3a26817450d6",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "f3288fde-b86b-4a86-9b72-3a26817450d6",
     "kernelId": "b83cabf1-1f53-48d7-b924-4b8494b9f03d"
    }
   },
   "source": [
    "# Augmentation image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30bc4a5-28f4-40af-bad8-665349a21065",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "a30bc4a5-28f4-40af-bad8-665349a21065",
     "kernelId": "b83cabf1-1f53-48d7-b924-4b8494b9f03d",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "  #tf.keras.layers.experimental.preprocessing.Resizing(WIDTH, HEIGHT),\n",
    "  tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
    "  #tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset= -1),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomRotation(0.5),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomZoom(0.2)\n",
    "])\n",
    "data_augmentation2 = tf.keras.Sequential([\n",
    "  #tf.keras.layers.experimental.preprocessing.Resizing(WIDTH, HEIGHT),\n",
    "  tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
    "  #tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset= -1),\n",
    "  #tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "  #tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "  #tf.keras.layers.experimental.preprocessing.RandomZoom(0.1)\n",
    "])\n",
    "\n",
    "train_ds_augmentation=train_ds.map(lambda image, label: (data_augmentation(image, training=True), label),  num_parallel_calls=AUTOTUNE)\n",
    "val_ds_augmentation=val_ds.map(lambda image, label: (data_augmentation(image, training=True), label), num_parallel_calls=AUTOTUNE)\n",
    "mylogs.info(f'train_ds_augmentation {len(train_ds_augmentation)}    val_ds_augmentation {len(val_ds_augmentation)} ')\n",
    "mylogs.info('Augmention Complete')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c14fa12-4056-4940-9807-2a4d6cedbd77",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "2c14fa12-4056-4940-9807-2a4d6cedbd77",
     "kernelId": "b83cabf1-1f53-48d7-b924-4b8494b9f03d"
    }
   },
   "source": [
    "# Create  CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efa6327-e7bc-4b92-95c0-984cebfe3a40",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "6efa6327-e7bc-4b92-95c0-984cebfe3a40",
     "kernelId": "b83cabf1-1f53-48d7-b924-4b8494b9f03d",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "opt=tf.keras.optimizers.Adam( learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, amsgrad=False)\n",
    "CNN_layers=[\n",
    "    {\"filters\":16, \"kernel\":5,\"kernel_regulazire\":False,\"batchnormalization\":False,\"poolmax\":True},\n",
    "    {\"filters\":16, \"kernel\":5,\"kernel_regulazire\":False,\"batchnormalization\":False,\"poolmax\":True},\n",
    "    {\"filters\":32, \"kernel\":3,\"kernel_regulazire\":False,\"batchnormalization\":False,\"poolmax\":True},\n",
    "    {\"filters\":32, \"kernel\":3,\"kernel_regulazire\":False,\"batchnormalization\":False,\"poolmax\":True},\n",
    "]\n",
    "    \n",
    "\n",
    "input_tensor = tf.keras.Input(shape=(WIDTH,HEIGHT,1))\n",
    "for i,CNN_layer in enumerate(CNN_layers):\n",
    "    \n",
    "    if i==0:\n",
    "        CNN=input_tensor\n",
    "    \n",
    "    CNN=tf.keras.layers.Conv2D(filters=CNN_layer['filters'] ,\n",
    "                              kernel_size=CNN_layer['kernel'], \n",
    "                              padding='same', \n",
    "                              activation=\"relu\",\n",
    "                              kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
    "                              bias_initializer=tf.keras.initializers.Zeros()\n",
    "                              #, kernel_regularizer=tf.keras.regularizers.l2(0.01)\n",
    "                              )(CNN)  \n",
    "\n",
    "    if CNN_layer['batchnormalization']==True:\n",
    "        CNN=tf.keras.layers.BatchNormalization(axis=-1)(CNN)\n",
    "\n",
    "    if  CNN_layer['poolmax']==True:\n",
    "        CNN = tf.keras.layers.MaxPool2D(pool_size=(2, 2),padding='same')(CNN)\n",
    "\n",
    "CNN=tf.keras.layers.Flatten(name=\"FLATTEN\")(CNN)\n",
    "CNN= tf.keras.layers.Dense(64 ,name='FC_1',activation=\"relu\")(CNN)\n",
    "CNN= tf.keras.layers.Dense(32 ,name='FC_2',activation=\"relu\")(CNN)\n",
    "CNN= tf.keras.layers.Dense(1 ,name='FC_3',activation=\"linear\")(CNN)\n",
    "\n",
    "model= tf.keras.Model(inputs=input_tensor, outputs=CNN,name='model_count_insects_final_2' )\n",
    "model.compile(optimizer=opt,\n",
    "              loss=tf.keras.losses.MeanSquaredError(),\n",
    "              metrics=['mae'])\n",
    "\n",
    "mylogs.info(model.summary())\n",
    "path_saved_model=os.path.join(saved_folder_path,f\"{model.name}.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71763bff-90e4-486f-957c-d0b3a403f102",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "71763bff-90e4-486f-957c-d0b3a403f102",
     "kernelId": "b83cabf1-1f53-48d7-b924-4b8494b9f03d"
    }
   },
   "source": [
    "## Evalute model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd90f54-4215-46e6-977d-dda115cc9203",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "6bd90f54-4215-46e6-977d-dda115cc9203",
     "kernelId": "b83cabf1-1f53-48d7-b924-4b8494b9f03d",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "val_ds_a=val_ds.map(lambda image,label:(image/255,label),num_parallel_calls=AUTOTUNE)\n",
    "loss0,mae = model.evaluate(val_ds_a,verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf268eb-6fa7-493e-89a0-76898d235545",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "ebf268eb-6fa7-493e-89a0-76898d235545",
     "kernelId": "b83cabf1-1f53-48d7-b924-4b8494b9f03d"
    }
   },
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586ae239-ffa4-4a08-9a8d-1c857042ee5b",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "586ae239-ffa4-4a08-9a8d-1c857042ee5b",
     "kernelId": "b83cabf1-1f53-48d7-b924-4b8494b9f03d"
    }
   },
   "source": [
    "## Prepare Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cc0e1e-adbf-4fc6-95ba-8644ba3924cc",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": true,
     "id": "b8cc0e1e-adbf-4fc6-95ba-8644ba3924cc",
     "kernelId": "b83cabf1-1f53-48d7-b924-4b8494b9f03d",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "initial_epochs = 250\n",
    "\n",
    "logdir = os.path.join('logs', f'{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}')\n",
    "mylogs.info(f'logdir {logdir}')\n",
    "\n",
    "\n",
    "checkpoint_folder_path=os.path.join(check_point_folder,f'{model.name}')\n",
    "\n",
    "!mkdir {checkpoint_folder_path}\n",
    "\n",
    "checkpoint_filepath=os.path.join(checkpoint_folder_path,'weights-improvement-{epoch:02d}-{val_loss:.2f}.hdf5')\n",
    "\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True\n",
    "    )\n",
    "\n",
    "history_log_file=os.path.join(history_log_folder_path,f'{model.name}-log.csv')\n",
    "history_logger_callback=tf.keras.callbacks.CSVLogger(history_log_file, separator=\",\", append=True)\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=1)\n",
    "\n",
    "callbacks=[tensorboard_callback,model_checkpoint_callback,history_logger_callback]\n",
    "mylogs.info('pretraining ok')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898db798-b5af-4062-aa00-284393e0bc4c",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "898db798-b5af-4062-aa00-284393e0bc4c",
     "kernelId": "b83cabf1-1f53-48d7-b924-4b8494b9f03d"
    }
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd854952-1f28-4fbc-85f3-17ee7f113955",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "cd854952-1f28-4fbc-85f3-17ee7f113955",
     "kernelId": "b83cabf1-1f53-48d7-b924-4b8494b9f03d",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "mylogs.info(f'{model.name}  Start {datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}')\n",
    "\n",
    "%tensorboard --logdir logs\n",
    "\n",
    "  \n",
    "model.fit(train_ds_augmentation,\n",
    "                      epochs=initial_epochs,\n",
    "                      validation_data=val_ds_augmentation,\n",
    "                      batch_size=BATCH_SIZE,\n",
    "                      callbacks=callbacks,\n",
    "                      verbose=2\n",
    "                      )\n",
    "\n",
    "\n",
    "model.save(path_saved_model)\n",
    "mylogs.info(f' Model saved in {path_saved_model}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8155462c-181e-46c4-a283-addd2b3431c4",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "8155462c-181e-46c4-a283-addd2b3431c4",
     "kernelId": "b83cabf1-1f53-48d7-b924-4b8494b9f03d"
    }
   },
   "source": [
    "## Save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18f3a85-9058-4656-936f-ea10a7514313",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "execution_count": 13,
     "id": "d18f3a85-9058-4656-936f-ea10a7514313",
     "kernelId": "b83cabf1-1f53-48d7-b924-4b8494b9f03d",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "path_saved_model=os.path.join(saved_folder_path,f\"{model.name}.h5\")\n",
    "model.save(path_saved_model)\n",
    "print(f' Model saved in {path_saved_model}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc286e3f-e37d-43c7-9060-95414859e058",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "bc286e3f-e37d-43c7-9060-95414859e058",
     "kernelId": "b83cabf1-1f53-48d7-b924-4b8494b9f03d"
    }
   },
   "source": [
    "## Evaluate model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84086528-384b-4f9d-94da-4ce9deea400e",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "execution_count": 14,
     "id": "84086528-384b-4f9d-94da-4ce9deea400e",
     "kernelId": "b83cabf1-1f53-48d7-b924-4b8494b9f03d",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model_ev = tf.keras.models.load_model(path_saved_model)\n",
    "val_ds_a=val_ds.map(lambda image,label:(image/255,label),num_parallel_calls=AUTOTUNE)\n",
    "loss0,mae = model_ev.evaluate(val_ds_a,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28585ded-dd6b-4397-98ee-29a20d125aa3",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "28585ded-dd6b-4397-98ee-29a20d125aa3",
     "kernelId": "b83cabf1-1f53-48d7-b924-4b8494b9f03d"
    }
   },
   "source": [
    "## Accure model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257df51d-a11a-4b56-a6ae-8f0af440376e",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "execution_count": 15,
     "id": "257df51d-a11a-4b56-a6ae-8f0af440376e",
     "kernelId": "b83cabf1-1f53-48d7-b924-4b8494b9f03d",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#check_point_file=os.path.join(check_point_folder,'{model.name}-weights-improvement-61-0.16.hdf5')\n",
    "#print(check_point_file)\n",
    "#model.load_weights(check_point_file)\n",
    "#model = tf.keras.models.load_model(path_saved_model)\n",
    "\n",
    "batch_prediction_floor = []\n",
    "batch_prediction_round = []\n",
    "batch_truth = []\n",
    "count=0\n",
    "\n",
    "for image, label in val_ds.unbatch():\n",
    "    batch_truth.append(label)\n",
    "\n",
    "    input_data =(np.float32(image)/255)\n",
    "    input_data = np.expand_dims(input_data, axis=0)\n",
    "    #print(input_data.shape)\n",
    "    output_data=model.predict(input_data)\n",
    "\n",
    "    #print(f'output_data {output_data}')\n",
    "    predictions=np.floor(np.array(output_data).item(0))\n",
    "    predictions_round=np.around(np.array(output_data).item(0))\n",
    "    #print(f'predictions {predictions}')\n",
    "    count=count+1\n",
    "    batch_prediction_floor.append(predictions)\n",
    "    batch_prediction_round.append(predictions_round)\n",
    "mylogs.info(f'Number of test Images {count}')\n",
    "tflite_accuracy = tf.keras.metrics.Accuracy()\n",
    "tflite_accuracy(batch_prediction_floor, batch_truth)\n",
    "mylogs.info(\"TF Lite accuracy: {:.3%}\".format(tflite_accuracy.result()))\n",
    "\n",
    "\n",
    "tflite_accuracy_round = tf.keras.metrics.Accuracy()\n",
    "tflite_accuracy_round(batch_prediction_round, batch_truth)\n",
    "mylogs.info(\"TF Lite accuracy round : {:.3%}\".format(tflite_accuracy_round.result()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864d0196-75de-400c-85b0-7478d30e895f",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "864d0196-75de-400c-85b0-7478d30e895f",
     "kernelId": "b83cabf1-1f53-48d7-b924-4b8494b9f03d"
    }
   },
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d297577-0594-423f-8ca6-366ca6675075",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "execution_count": 16,
     "id": "1d297577-0594-423f-8ca6-366ca6675075",
     "kernelId": "b83cabf1-1f53-48d7-b924-4b8494b9f03d",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "modelpredict = tf.keras.models.load_model(path_saved_model)\n",
    "print(f'Load model {path_saved_model}')\n",
    "plt.figure(figsize=(10, 20))\n",
    "for images, labels in val_ds.shuffle(64).take(1):\n",
    "  for i in range(20):\n",
    "    \n",
    "    plt.imshow(images[i][:,:,0],cmap='gray', vmin=0, vmax=255)\n",
    "    plt.show()\n",
    "\n",
    "    input_data =(np.float32(images[i])/255)\n",
    "    input_data = np.expand_dims(input_data, axis=0)\n",
    "    pred=modelpredict.predict(input_data)\n",
    "    predictions_floor=np.floor(np.array(pred).item(0))\n",
    "    predictions_round=np.around(np.array(pred).item(0))\n",
    "    print(f'predict={pred}  floor{predictions_floor}  round{predictions_round} label= {labels[i]}')\n",
    "    "
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
